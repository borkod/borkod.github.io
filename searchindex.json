{"categories":[],"posts":[{"content":"Microsoft Ignite the Tour conference is a two-day version of Microsoft's annual Ignite technology conference that Microsoft is bringing to a number of cities around the world. Last week I had the opportunity to attend the conference in Toronto. As usual at these types of events, there was \u0026ldquo;The Hub\u0026rdquo;, a central meeting place where large number of sponsors had booths set up demonstrating their products or services and giving out SWAG. The Hub also contained three theaters that featured 15-minute lightning sessions on technical topics from Microsoft experts or customer discussion panels. The conference agenda was also packed with deep-dive breakout sessions on large variety of topics. ‚ö°Ô∏è ‚ÄúHighlights from #MSIgniteTheTour Toronto Day 1‚Äùhttps://t.co/oPvCLNWS1a\n\u0026mdash; Microsoft IT Pro Canada (@MS_ITProCA) January 8, 2020  Learning Paths A unique and differentiating aspect of this conference was that the breakout sessions consisted of Learning Paths. These were essentially educational sessions connected around a common theme. Learning Paths focused on several themes, including Dynamics 365, Microsoft Teams, Windows, AI, Azure, among others. I attended sessions of the two Learning Path tracks that seemed most pertinent to me, Developing cloud native applications and Modernizing web applications and data.\nEach Learning Path breakout session aimed its attention at a different technical aspect, e.g. migrating data, compute or data storage services, operations, etc. Another interesting and unique element of the learning paths is that they were all linked via a common story dealing with a fictitious company \u0026ldquo;Tailwind Traders\u0026rdquo;. Every individual session presented a scenario that was used to illustrate some technical capabilities and services provided by Azure. Tailwind Traders is a collection of Azure reference apps used to showcase Azure technology. Although this scenario-based format is very effective as a teaching method, I think I would have preferred if breakout sessions involved real-life customer stories instead.\nThe sessions were capped at 45 minutes and there was no time for any Q and A during the sessions. Instead, the presenters were available for Q and A at the Microsoft Showcase booth in The Hub. I didn't particularly like this. There is a lot of learning value in hearing questions or issues brought up by others in the audience and having answers shared with the entire group.\nAll breakout sessions used speech to text to provide real-time subtitles of the presenter lecture. Kudos go to Microsoft for improving accessibility to the conference sessions in this way. üëç\nFor myself, the highlights of the breakout sessions were the two presentations given by Aaron Wislang (@as_w). The first session was APPS30: Modernizing Your Application with Containers. This was followed by a second session on APPS40: Consolidating Infrastructure with Azure Kubernetes Service. Both presentations were very well prepared and adeptly communicated to the audience. The content of the talks presented a great review of fundamentals of container technology and an introduction to the related services in the Azure cloud platform. The demos were also effective in illustrating the concepts and services discussed in the presentation. I also recommend visiting Aaron's compilation of useful Kubernetes resources.\nAnother notable session I attended was by April Edwards (@theapriledwards) titled MOD50 - Managing Delivery of your App via DevOps. The talk was very well polished and presented. It provided the audience a very good introductory overview DevOps and CI/CD. I liked that there was a focus on people and culture as much as technology. For the technical aspects, the session presented a good introduction to Azure DevOps for those not familiar with the platform. It included demonstrations of Azure DevOps integration with Github Actions, canary deployments utilizing deployment slots, and approval gates.\nTheater Talks One of the theater talks with special interest to me was the panel discussion with the City of Ottawa on transformation and upskilling. The sessions turned out to be especially popular as there was a very large audience gathered around the theater area. \u0026quot;As we embark on this journey of transformation, the use of technology has changed from what it used to be.\u0026quot; - Fawad Ahmed, City of Ottawa @ottawacity #MSIgniteTheTour pic.twitter.com/ukvDSV0ueH\n\u0026mdash; Microsoft Canada (@microsoftcanada) January 8, 2020  The panel conversation focused on City of Ottawa's digital transformation journey. The speakers shared insights around challenges and lessons learned as they adopted Dynamics 365 and Azure platforms to transform city's public services.\nAnnouncements During the conference, Microsoft made a news release announcing addition of Availability Zones in the Canada Central region and increased compute capacity in both Canadian regions. This is great news for Canada and will positively impact cloud adoption here. Today, at #MSEnvisionTheTour, we announced that we are making significant investments in our üá®üá¶ cloud with the addition of #Azure Availability Zones, and new Azure ExpressRoute in Vancouver. Read more about our news here: https://t.co/yMUuq7KlZP pic.twitter.com/3Bkv2hrsG5\n\u0026mdash; Microsoft Canada (@microsoftcanada) January 9, 2020  Free Certifications Microsoft Learn section of the Microsoft Showcase booth was always buzzing with people interested in finding out more about trainings and certifications offered by Microsoft. All conference attendees were able to receive an offer for a free certification exam voucher. I am definitely eager to take advantage of this on one of my future tests!\nMicrosoft Reactor - Toronto Also in the Microsoft Showcase area, I was very excited to learn about Microsoft Reactor initiative and its newly opened Toronto location. This seems like a tremendous program and an invaluable resource. I'd love to see it expanded to more cities in Canada (especially Ottawa! üòä).\nFinal Thoughts This was my first Microsoft Ignite experience. Although it was two very busy days, the conference was a very positive experience. It was a great way to kick off 2020 and I am excited to see where Azure goes over the next twelve months!\n","id":0,"section":"posts","summary":"Microsoft Ignite the Tour conference is a two-day version of Microsoft's annual Ignite technology conference that Microsoft is bringing to a number of cities around the world. Last week I had the opportunity to attend the conference in Toronto. As usual at these types of events, there was \u0026ldquo;The Hub\u0026rdquo;, a central meeting place where large number of sponsors had booths set up demonstrating their products or services and giving out SWAG.","tags":["Azure","Microsoft","Ignite","Microsoft Ignite the Tour","Toronto","Recap"],"title":"Microsoft Ignite the Tour: Toronto Recap","uri":"https://borkod.github.io/2020/01/microsoft-ignite-the-tour-toronto-recap/","year":"2020"},{"content":"In late November of 2019, AWS announced a new specialty certification focusing specifically on database technologies. The AWS Certified Database - Specialty Exam beta period started in early December of 2019 with the standard certification exam availability target date being April of 2020. At the start of December, I participated in the beta attempting the beta exams. As of this writing, I do not know my results and whether on not I achieved the certification. Nevertheless, I thought it would be useful to share my experience. I'll try to list the topics covered by the exam questions, and provide some insight and resources that are helpful in preparing for the exam.\nThe contents of this blog post can also be found in my GitHub repo here.\nExam Description The database certification exam covers five domains:\n Domain 1: Workload-Specific Database Design (26%) Domain 2: Deployment and Migration (20%) Domain 3: Management and Operations (18%) Domain 4: Monitoring and Troubleshooting (18%) Domain 5: Database Security (18%)  The exam's goal is to test user's competence to:\n Understand the various AWS database services Recommend and design database solutions appropriate to satisfy specific problem requirements  AWS suggests that the examinee has:\n Minimum of 5 years of experience working with relational and NoSQL databases, including on-prem and cloud based implementations Minimum of 2 years of hand-on experience with AWS  Exam Topics  Amazon RDS is one of the core services offered by AWS, so having good understanding and thorough knowledge of this service is critical to succeeding in the exam.  You should have expertise in analyzing and identifying requirements / use cases when a relational database (and specifically RDS) is the appropriate solution. You should also have a good understanding of the service capabilities and limitations. Multi-AZ: Know technical details of its implementation and when it is appropriate (e.g. disaster recovery scenarios) Read-Replicas: Know technical details and in what situations is it useful (e.g. off-loading read traffic) Know the numerous engine options RDS has available  There are engine specific questions, so you should have some familiarity with each engine (e.g. Oracle TDE, PostgreSQL specific capabilities)   Backups Option Groups DB Parameter Groups SQL Performance Insights (what is it, when is it applicable, and how is it different from CloudWatch)   Alongside RDS, DynamoDB is probably the most crucial of AWS database services. You should know it inside and out.  Understand Primary Keys/Partition Keys/Sort Keys. Given a particular scenario, be able to design/choose them. Global Secondary Indexes / Local Secondary Indexes. Understand difference between them and applicable use cases. DynamoDB Streams Global Tables (and its use cases) Data Modeling  Partition Sharding (e.g. adding random suffix) Composite Keys   Design patterns and best practices Querying and Filtering DAX (vs ElastiCache) Have a good understanding of the underlying technical architecture   Amazon Aurora  Understand the technical architecture and use cases Difference between Aurora Read Replicas/RDS Read Replicas Scaling of Aurora Understand Aurora Serverless Understand Aurora Clones and when to you should use them   CloudWatch  Understand the service functionality How to use in troubleshooting scenarios Performance monitoring and notification/alerting scenarios   Database Migration  There are questions around AWS SCT (Schema Conversion Tool) and AWS DMS (Database Migration Service). You should have a general understanding of both, difference between them, and when you would use one vs the other.   ElastiCache  Have a good understanding of use cases when caching is appropriate Focus on Redis Understand Redis architecture, Multi-AZ, etc. Understand various caching strategies (Lazy Loading, Write-Through) and benefits/limitation of each   DocumentDB  I don't recall many questions on this service, however you should have general familiarity with it   Redshift  Have a general understanding of data-warehouse topics and columnar storage Be familiar with technical architecture (single node deployment / cluster with leader and compute nodes) Be familiar with Redshift Spectrum Understand use cases for Redshift (e.g. Business Intelligence and Reporting). Be able to differentiate applicability of Redshift vs RDS.   Neptune  I don't recall many questions here. However, you should have general understanding of graph database concepts and graph database applications. I suggest being familiar with its technical architecture Know supported APIs (Gremlin, SPARQL) and models (Property Graph/TinkerPop and W3C RDF/SPARQL)   Security  Understand options and solutions for data encryption (both data at rest and data in transit) Authentication options and capabilities Access Management (IAM) Have good understanding of services like Parameter Store and KMS   Networking  Understand how to integrate various services with VPC (e.g. VPC Endpoints) Know how to secure access at network level   Solutions Architecture  There were a number of questions very reminiscent of questions from AWS Solutions Architect Exam. I strongly suggest attaining AWS Solutions Architect Associate Certification before attempting this specialty exam. Understand AWS Lambda and how it can be used in conjunction with all the other services mentioned above Expect questions on High Availability, Disaster Recovery, and Fault Tolerance   Deployment and CI/CD  There were quite a few (more than I expected) questions relating to deployment and CI/CD concepts. I would strongly suggest attaining the AWS DevOps Engineer Professional certification prior to writing this specialty exam (or at least AWS Developer Associate Certification). You need to understand the various DevOps services AWS offers (e.g. CloudFormation, CodeBuild, CodeDeploy) and how they can be utilized to assist deployment scenarios.    General Tips As mentioned above, I strongly suggest having both AWS Solutions Architect - Associate and AWS Certified Developer - Associate certifications (or preferably AWS DevOps Engineer - Professional) prior to entering to write this specialty exam. The experience and knowledge required to attain those certifications will go a long way in helping you do well in this exam.\nAs suggested by AWS, you should have significant experience designing and implementing solutions consisting of various database technologies. This experience should include considerable understanding and practical use of AWS services.\nLastly, I suggest reviewing official AWS documentation, AWS Whitepapers \u0026amp; Guides, blogs, and videos. In particular, I found advanced level Re:Invent and Online Tech Talk videos particularly useful.\nResources Below is a list of few links I found especially informative.\nAWS Re:Invent Videos and Online Tech Talks:  Amazon Relational Database Service (Amazon RDS) AWS re:Invent 2017: Deep Dive on Amazon Relational Database Service (RDS) (DAT302) AWS re:Invent 2018: Aurora Serverless: Scalable, Cost-Effective Application Deployment (DAT336) Migrating Microsoft SQL to AWS - AWS Online Tech Talks  Contains a good demo of DMS   AWS re:Invent 2017: ElastiCache Deep Dive: Best Practices and Usage Patterns (DAT305) AWS re:Invent 2018: ElastiCache Deep Dive: Design Patterns for In-Memory Data Stores (DAT302-R1) AWS re:Invent 2018: Amazon DynamoDB Under the Hood: How We Built a Hyper-Scale Database (DAT321) AWS re:Invent 2018: Accelerate Database Development and Testing with Amazon Aurora (DAT313) Data Design and Modeling for Microservices AWS re:Invent 2017: Best Practices for Data Warehousing with Amazon Redshift \u0026amp; Redshift Spectrum (ABD304) AWS re:Invent 2018: Amazon DynamoDB Deep Dive: Advanced Design Patterns for DynamoDB (DAT401)  AWS Whitepapers \u0026amp; Guides  An Overview of AWS Cloud Data Migration Services Migrating Applications Running Relational Databases to AWS: Best Practices Guide AWS Database Migration Service Best Practices Migrating Your Databases to Amazon Aurora Best Practices for Migrating MySQL Databases to Amazon Aurora Strategies for Migrating Oracle Databases to AWS Best Practices for Running Oracle Database on AWS Deploying Microsoft SQL Server on AWS Best Practices for Deploying Microsoft SQL Server on AWS Performance at Scale with Amazon ElastiCache Database Caching Strategies Using Redis Getting Started with Amazon DocumentDB (with MongoDB Compatibility)  Final Thoughts In my opinion, AWS Database Specialty is an excellent addition to the AWS Certification program. Database technologies are an integral and crucial part of any cloud based solution. Having a strong competency in these technologies is critical to being a successful architect and designing apt solutions.\nI hope this guide and contents within are helpful to those preparing to attempt the exam in the future.\nGood Luck!\n","id":1,"section":"posts","summary":"In late November of 2019, AWS announced a new specialty certification focusing specifically on database technologies. The AWS Certified Database - Specialty Exam beta period started in early December of 2019 with the standard certification exam availability target date being April of 2020. At the start of December, I participated in the beta attempting the beta exams. As of this writing, I do not know my results and whether on not I achieved the certification.","tags":["AWS","Certification","Database","Study Guide"],"title":"AWS Certified Database - Specialty Exam Preparation Guide and Study Tips","uri":"https://borkod.github.io/2020/01/aws-certified-database-specialty-exam-guide/","year":"2020"}],"tags":[{"title":"AWS","uri":"https://borkod.github.io/tags/aws/"},{"title":"Azure","uri":"https://borkod.github.io/tags/azure/"},{"title":"Certification","uri":"https://borkod.github.io/tags/certification/"},{"title":"Database","uri":"https://borkod.github.io/tags/database/"},{"title":"Ignite","uri":"https://borkod.github.io/tags/ignite/"},{"title":"Microsoft","uri":"https://borkod.github.io/tags/microsoft/"},{"title":"Microsoft Ignite the Tour","uri":"https://borkod.github.io/tags/microsoft-ignite-the-tour/"},{"title":"Recap","uri":"https://borkod.github.io/tags/recap/"},{"title":"Study Guide","uri":"https://borkod.github.io/tags/study-guide/"},{"title":"Toronto","uri":"https://borkod.github.io/tags/toronto/"}]}